{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb1d179-7fc6-4803-a2ee-98e944971b16",
   "metadata": {},
   "source": [
    " # Linear Regression: Analytic Solution, Full-Batch Gradient Descent, and Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d876072f-e814-47a1-bf33-1ed3a855018f",
   "metadata": {},
   "source": [
    "This analysis will implement Linear Regression using three methods: the Analytic Solution, Full-Batch Gradient Descent, and Stochastic Gradient Descent. We will calculate the regression coefficients and evaluate the model's performance using Sum Squared Error (SSE) and R-squared (R¬≤) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f088d565-25d1-4e86-a9fd-a71302f27ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22fad972-c312-4c9c-83bd-54cfac3f6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "y = np.array([1, 3, 2, 5, 7, 8, 8, 9, 10, 12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999e7e68-beaa-428a-b4e6-e682341d660f",
   "metadata": {},
   "source": [
    "Using the manually calculated coefficients \n",
    "ùëè0 = 1.235\n",
    "b1 = 1.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bccc2580-e734-43f0-bb6b-aa1e368b569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "b0 = 1.235\n",
    "b1 = 1.17\n",
    "\n",
    "# Predict y values\n",
    "y_pred_manual = b0 + b1 * x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341e8d9b-1bd1-4685-8c16-d78f0b056c7b",
   "metadata": {},
   "source": [
    "Calculating the Sum Squared Error (SSE) and R-squared (R¬≤) for these predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10254299-37f7-4fba-b760-9f783ca2a77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " R-squared: 0.9525379746835443\n",
      " Sum Squared Error: 5.624249999999998\n"
     ]
    }
   ],
   "source": [
    "# Calculate Sum Squared Error (SSE)\n",
    "SSE_manual = np.sum((y - y_pred_manual) ** 2)\n",
    "\n",
    "# Calculate R-squared (R¬≤)\n",
    "SS_total = np.sum((y - np.mean(y)) ** 2)\n",
    "R2_manual = 1 - (SSE_manual / SS_total)\n",
    "print(f\" R-squared: {R2_manual}\")\n",
    "print(f\" Sum Squared Error: {SSE_manual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6a0be-81d2-4067-915b-220d8ce4d31d",
   "metadata": {},
   "source": [
    "### Full-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a1379b-d66e-4643-a7c4-6b9d77d5229c",
   "metadata": {},
   "source": [
    "We initialize the parameters (coefficients) to zero. The learning rate controls how big a step we take in the direction of the gradient at each iteration. The number of iterations specifies how many times we update the coefficients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10d6277c-0797-4ea5-9d9f-4a362409e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize coefficients\n",
    "theta_gd = np.zeros(2)  # Initialize theta (b0 and b1) to zero\n",
    "learning_rate = 0.01  # Set the learning rate\n",
    "num_iterations = 1000  # Set the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc642c1b-5b75-4552-a2c5-9647e4365a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column of ones to x for the intercept term (bias)\n",
    "X = np.column_stack((np.ones(x.shape[0]), x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed08a2-1c21-4117-bbb1-ede837a83fd8",
   "metadata": {},
   "source": [
    "In this step, we perform the gradient descent algorithm, where we update the coefficients iteratively by moving in the direction of the negative gradient of the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4631e87-d8b2-43d9-9844-45f742709643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform gradient descent\n",
    "for _ in range(num_iterations):\n",
    "    # Calculate the gradient of the cost function\n",
    "    gradients = (X.T @ (X @ theta_gd - y)) / len(y)\n",
    "    # Update the coefficients by taking a step proportional to the learning rate\n",
    "    theta_gd -= learning_rate * gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123e4bab-ab54-48c3-b87d-a21ff34d0e15",
   "metadata": {},
   "source": [
    "Once we have the final coefficients from gradient descent, we make predictions and calculate the Sum Squared Error (SSE) and R-squared (R¬≤) to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "069d6713-e929-487b-a4de-b04be1dee580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict y values using the final coefficients\n",
    "y_pred_gd = X @ theta_gd\n",
    "\n",
    "# Calculate SSE to measure the total deviation of the predictions from the actual values\n",
    "SSE_gd = np.sum((y - y_pred_gd) ** 2)\n",
    "\n",
    "# Calculate R-squared (R¬≤) to measure how well the model explains the variance in the data\n",
    "R2_gd = 1 - (SSE_gd / SS_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc53ea06-5c55-4503-9c84-09ab7377e417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final coefficients (b0, b1): [1.17580361 1.17935476]\n",
      "Sum Squared Error (SSE): 5.634861529064237\n",
      "R-squared (R¬≤): 0.9524484259150697\n"
     ]
    }
   ],
   "source": [
    "# Output the final coefficients, SSE, and R¬≤\n",
    "print(f\"Final coefficients (b0, b1): {theta_gd}\")\n",
    "print(f\"Sum Squared Error (SSE): {SSE_gd}\")\n",
    "print(f\"R-squared (R¬≤): {R2_gd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1ca2f3-469b-46a5-b26a-d00b09988381",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c4539935-c024-4fc4-b7ae-236644185c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize coefficients\n",
    "theta_sgd = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a1ecf451-d990-4ecd-ba58-cd9317cc8b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform stochastic gradient descent\n",
    "for _ in range(num_iterations):\n",
    "    i = np.random.randint(0, len(y))\n",
    "    gradients = (X[i].reshape(1, -1).T @ (X[i].reshape(1, -1) @ theta_sgd - y[i])).reshape(2,)\n",
    "    theta_sgd -= learning_rate * gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b3db703-9cb4-46a9-b99d-c84597b84af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final coefficients (b0, b1): [1.11041811 1.26582508]\n",
      "Sum Squared Error (SSE): 7.326818650335652\n",
      "R-squared (R¬≤): 0.9381703067482223\n"
     ]
    }
   ],
   "source": [
    "# Predict y values\n",
    "y_pred_sgd = X @ theta_sgd\n",
    "\n",
    "# Calculate SSE and R¬≤\n",
    "SSE_sgd = np.sum((y - y_pred_sgd) ** 2)\n",
    "R2_sgd = 1 - (SSE_sgd / SS_total)\n",
    "print(f\"Final coefficients (b0, b1): {theta_sgd}\")\n",
    "print(f\"Sum Squared Error (SSE): {SSE_sgd}\")\n",
    "print(f\"R-squared (R¬≤): {R2_sgd}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
